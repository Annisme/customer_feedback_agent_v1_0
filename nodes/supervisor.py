import json
from langchain_core.messages import AIMessage, HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.types import interrupt, Command


INTENT_PARSE_PROMPT = """ä½ æ˜¯ä¸€å€‹å®¢æœå›é¥‹åˆ†æåŠ©ç†çš„æ„åœ–è§£æå™¨ã€‚è«‹åˆ†æä½¿ç”¨è€…çš„æŒ‡ä»¤ï¼Œåˆ¤æ–·ä»–å€‘æƒ³è¦ä»€éº¼ã€‚

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{
    "intent": "full_analysis | specific_query | visualization_only | report_only",
    "time_range": "ä½¿ç”¨è€…æåˆ°çš„æ™‚é–“ç¯„åœï¼Œä¾‹å¦‚ '2024Q4'ã€'æœ€è¿‘ä¸‰å€‹æœˆ'ï¼Œè‹¥æœªæåŠå‰‡ç‚º null",
    "chart_types": ["pie", "line", "bar"] ä¸­ä½¿ç”¨è€…éœ€è¦çš„åœ–è¡¨é¡å‹ï¼Œè‹¥æœªæŒ‡å®šå‰‡ç‚º [],
    "needs_clarification": true/falseï¼ŒæŒ‡ä»¤æ˜¯å¦æ¨¡ç³Šä¸æ¸…éœ€è¦é‡æ¸…,
    "clarification_question": "è‹¥éœ€è¦é‡æ¸…ï¼Œè¦å•ä½¿ç”¨è€…çš„å•é¡Œï¼Œå¦å‰‡ç‚º null"
}

æ„åœ–åˆ¤æ–·è¦å‰‡ï¼š
- full_analysis: ä½¿ç”¨è€…è¦æ±‚å®Œæ•´åˆ†æã€å…¨é¢åˆ†æã€æˆ–æœªæ˜ç¢ºæŒ‡å®šç¯„åœçš„åˆ†æ
- specific_query: ä½¿ç”¨è€…åªæƒ³çŸ¥é“æŸå€‹ç‰¹å®šæ•¸æ“šï¼ˆå¦‚å›é¥‹æ•¸é‡ã€æŸæ™‚æ®µçš„çµ±è¨ˆï¼‰
- visualization_only: ä½¿ç”¨è€…åªè¦æ±‚åœ–è¡¨æˆ–è¦–è¦ºåŒ–
- report_only: ä½¿ç”¨è€…åªè¦æ±‚ç”¢å‡ºå ±å‘Š

needs_clarification åˆ¤æ–·è¦å‰‡ï¼š
- è‹¥æŒ‡ä»¤éæ–¼æ¨¡ç³Šï¼ˆä¾‹å¦‚åªèªªã€Œåˆ†æã€ä½†æ²’æœ‰å…¶ä»–è„ˆçµ¡ï¼‰ï¼Œè¨­ç‚º true
- è‹¥æŒ‡ä»¤æ˜ç¢ºï¼ˆä¾‹å¦‚ã€Œå¹«æˆ‘åšå®Œæ•´åˆ†æã€ã€ã€Œç•«ä¸€å¼µåœ“é¤…åœ–ã€ï¼‰ï¼Œè¨­ç‚º false
- è‹¥ä½¿ç”¨è€…å·²æä¾› Google Sheet URL æˆ–ä¹‹å‰å·²æœ‰è³‡æ–™ï¼ŒæŒ‡ä»¤é€šå¸¸è¶³å¤ æ¸…æ¥š"""

PLAN_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹å®¢æœå›é¥‹åˆ†æåŠ©ç†çš„ Supervisorã€‚ä½ çš„è·è²¬æ˜¯ï¼š
1. æ ¹æ“šä½¿ç”¨è€…æ„åœ–å’Œè§£æçµæœï¼Œç”Ÿæˆç²¾æº–çš„åŸ·è¡Œè¨ˆç•«ï¼ˆplanï¼‰
2. è¨ˆç•«æ‡‰è©²åªåŒ…å«ä½¿ç”¨è€…çœŸæ­£éœ€è¦çš„æ­¥é©Ÿ

å¯ç”¨çš„æ­¥é©Ÿæœ‰ï¼š
- fetch: å¾ Google Sheet è®€å–è³‡æ–™
- cluster: é€²è¡Œæƒ…æ„Ÿåˆ†æèˆ‡æ„è¦‹åˆ†ç¾¤
- knowledge_map: ç”Ÿæˆ Knowledge Map éšå±¤æ¨¹ç‹€åœ–
- wordcloud: ç”Ÿæˆæ–‡å­—é›²
- chart: ç”Ÿæˆåœ–è¡¨ï¼ˆåœ“é¤…åœ–ã€æŠ˜ç·šåœ–ã€é•·æ¢åœ–ï¼‰
- report: ç”Ÿæˆæ”¹å–„å»ºè­°å ±å‘Š

ä½¿ç”¨è€…æ„åœ–è§£æçµæœï¼š
{query_context}

è¨ˆç•«è¦å‰‡ï¼š
- æ¯æ¬¡åŸ·è¡Œéƒ½å¿…é ˆä»¥ fetch æ­¥é©Ÿé–‹é ­ï¼Œå› ç‚ºéœ€è¦å…ˆè®€å–è³‡æ–™æ‰èƒ½é€²è¡Œä»»ä½•åˆ†æ
- intent ç‚º full_analysis æ™‚ï¼Œä¾åºåŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿï¼šfetch â†’ cluster â†’ knowledge_map â†’ wordcloud â†’ chart â†’ report
- intent ç‚º specific_query æ™‚ï¼Œé€šå¸¸åªéœ€ fetch â†’ ç›¸é—œåˆ†ææ­¥é©Ÿ â†’ report
- intent ç‚º visualization_only æ™‚ï¼Œéœ€è¦ fetch â†’ ç›¸é—œåˆ†æ â†’ åœ–è¡¨ â†’ report
- intent ç‚º report_only æ™‚ï¼Œéœ€è¦ fetch â†’ å‰ç½®åˆ†ææ­¥é©Ÿ â†’ report
- è‹¥ä½¿ç”¨è€…æŒ‡å®šäº† chart_typesï¼Œåœ¨ explanation ä¸­èªªæ˜åªæœƒç”ŸæˆæŒ‡å®šçš„åœ–è¡¨
- æ¯æ¬¡åŸ·è¡Œéƒ½å¿…é ˆä»¥ report æ­¥é©Ÿçµå°¾ï¼Œå³ä½¿ä½¿ç”¨è€…åªè¦æ±‚éƒ¨åˆ†åˆ†æï¼Œä¹Ÿè¦ç”Ÿæˆå ±å‘Š

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
    "plan": ["æ­¥é©Ÿ1", "æ­¥é©Ÿ2", ...],
    "explanation": "å°è¨ˆç•«çš„ç°¡çŸ­èªªæ˜"
}}

æ­¥é©Ÿåç¨±å¿…é ˆæ˜¯ä¸Šè¿°å¯ç”¨æ­¥é©Ÿçš„è‹±æ–‡åç¨±ã€‚"""

ROUTE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹å®¢æœå›é¥‹åˆ†æåŠ©ç†çš„ Supervisorã€‚
ç›®å‰çš„åŸ·è¡Œè¨ˆç•«æ˜¯ï¼š{plan}
ç›®å‰å·²åŸ·è¡Œåˆ°ç¬¬ {current_step} æ­¥ã€‚

è«‹æ ¹æ“šç›®å‰ç‹€æ…‹æ±ºå®šä¸‹ä¸€æ­¥è¦åšä»€éº¼ã€‚
å¦‚æœæ‰€æœ‰æ­¥é©Ÿéƒ½å·²å®Œæˆï¼Œå›å‚³ "done"ã€‚
å¦å‰‡å›å‚³ä¸‹ä¸€æ­¥çš„æ­¥é©Ÿåç¨±ã€‚

åªå›å‚³æ­¥é©Ÿåç¨±ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""


def _get_llm():
    return ChatOpenAI(model="gpt-4.1", temperature=0)


def _parse_json_response(content: str) -> dict:
    """å¾ LLM å›æ‡‰ä¸­æ“·å– JSONã€‚"""
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0]
    elif "```" in content:
        content = content.split("```")[1].split("```")[0]
    return json.loads(content.strip())


def supervisor_node(state: dict) -> dict:
    """Supervisor ç¯€é»ï¼šå…©éšæ®µæ„åœ–è§£æ + è¨ˆç•«ç”Ÿæˆã€‚"""
    messages = state.get("messages", [])
    user_input = state.get("user_input", "")
    plan = state.get("plan")
    plan_approved = state.get("plan_approved", False)
    current_step = state.get("current_step", 0)
    query_context = state.get("query_context")

    llm = _get_llm()

    # æƒ…å¢ƒä¸€ï¼šå°šæœªæœ‰ planï¼Œéœ€è¦ç”Ÿæˆæ–°è¨ˆç•«
    if not plan:
        # â”€â”€ ç¬¬ä¸€éšæ®µï¼šæ„åœ–è§£æ â”€â”€
        if not query_context:
            intent_response = llm.invoke([
                {"role": "system", "content": INTENT_PARSE_PROMPT},
                {"role": "user", "content": f"ä½¿ç”¨è€…æŒ‡ä»¤ï¼š{user_input}"},
            ])

            try:
                query_context = _parse_json_response(intent_response.content)
            except (json.JSONDecodeError, IndexError):
                query_context = {
                    "intent": "full_analysis",
                    "time_range": None,
                    "chart_types": [],
                    "needs_clarification": False,
                    "clarification_question": None,
                }

        # è‹¥éœ€è¦é‡æ¸…ï¼Œé€é interrupt å‘ä½¿ç”¨è€…æå•
        if query_context.get("needs_clarification"):
            question = query_context.get("clarification_question", "è«‹å•æ‚¨å…·é«”æƒ³è¦ä»€éº¼æ¨£çš„åˆ†æï¼Ÿ")
            # æ¸…é™¤ needs_clarification ä»¥é¿å…å›è¦†å¾Œå†æ¬¡è§¸ç™¼
            query_context["needs_clarification"] = False
            return {
                "query_context": query_context,
                "awaiting_human": True,
                "interrupt_message": f"ğŸ¤” {question}",
                "messages": [AIMessage(content=f"ğŸ¤” {question}")],
            }

        # â”€â”€ ç¬¬äºŒéšæ®µï¼šè¨ˆç•«ç”Ÿæˆ â”€â”€
        plan_prompt = PLAN_SYSTEM_PROMPT.format(query_context=json.dumps(query_context, ensure_ascii=False))
        response = llm.invoke([
            {"role": "system", "content": plan_prompt},
            {"role": "user", "content": f"ä½¿ç”¨è€…æŒ‡ä»¤ï¼š{user_input}"},
        ])

        try:
            plan_data = _parse_json_response(response.content)
            new_plan = plan_data.get("plan", [])
            explanation = plan_data.get("explanation", "")
        except (json.JSONDecodeError, IndexError):
            new_plan = ["fetch", "cluster", "knowledge_map", "wordcloud", "chart", "report"]
            explanation = "å°‡åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹"

        # å¼·åˆ¶ç¢ºä¿ fetch ç‚ºè¨ˆç•«çš„ç¬¬ä¸€æ­¥ï¼ˆæ²’æœ‰è³‡æ–™å°±ç„¡æ³•åˆ†æï¼‰
        if "fetch" not in new_plan:
            new_plan.insert(0, "fetch")
        elif new_plan[0] != "fetch":
            new_plan.remove("fetch")
            new_plan.insert(0, "fetch")

        # å¼·åˆ¶ç¢ºä¿ report ç‚ºè¨ˆç•«çš„å€’æ•¸ç¬¬äºŒæ­¥
        if "report" not in new_plan:
            new_plan.append("report")
        elif new_plan[-1] != "report":
            new_plan.remove("report")
            new_plan.append("report")

        # å¼·åˆ¶ç¢ºä¿ evaluate ç‚ºè¨ˆç•«çš„æœ€å¾Œä¸€æ­¥ï¼ˆreport â†’ evaluateï¼‰
        if "evaluate" in new_plan:
            new_plan.remove("evaluate")
        new_plan.append("evaluate")

        # æ ¼å¼åŒ–è¨ˆç•«é¡¯ç¤º
        step_names = {
            "fetch": "è®€å– Google Sheet è³‡æ–™",
            "cluster": "é€²è¡Œæƒ…æ„Ÿåˆ†æèˆ‡æ„è¦‹åˆ†ç¾¤",
            "knowledge_map": "ç”Ÿæˆ Knowledge Map",
            "wordcloud": "ç”Ÿæˆæ–‡å­—é›²",
            "chart": "ç”Ÿæˆåœ–è¡¨ï¼ˆåœ“é¤…åœ–ã€æŠ˜ç·šåœ–ã€é•·æ¢åœ–ï¼‰",
            "report": "è¼¸å‡ºæ”¹å–„å»ºè­°å ±å‘Š",
            "evaluate": "å“è³ªè©•ä¼°",
        }
        plan_display = "\n".join(
            f"  {i+1}. {step_names.get(s, s)}" for i, s in enumerate(new_plan)
        )
        interrupt_msg = f"ğŸ“‹ åŸ·è¡Œè¨ˆç•«ï¼š\n{plan_display}\n\n{explanation}\n\næ˜¯å¦åŒæ„é–‹å§‹åŸ·è¡Œï¼Ÿ"

        return {
            "plan": new_plan,
            "query_context": query_context,
            "plan_approved": False,
            "current_step": 0,
            "awaiting_human": True,
            "interrupt_message": interrupt_msg,
            "messages": [AIMessage(content=interrupt_msg)],
        }

    # æƒ…å¢ƒäºŒï¼šæœ‰ plan ä½†å°šæœªè¢«ç¢ºèª â†’ ç­‰å¾…ç¢ºèªçµæœ
    if plan and not plan_approved:
        return {
            "plan_approved": True,
            "awaiting_human": False,
            "current_step": 0,
            "messages": [AIMessage(content="âœ… è¨ˆç•«å·²ç¢ºèªï¼Œé–‹å§‹åŸ·è¡Œ...")],
        }

    # æƒ…å¢ƒä¸‰ï¼šplan å·²ç¢ºèªï¼Œæ±ºå®šä¸‹ä¸€æ­¥è·¯ç”±
    if plan_approved and current_step < len(plan):
        next_step = plan[current_step]
        step_names = {
            "fetch": "è®€å–è³‡æ–™",
            "cluster": "åˆ†æåˆ†ç¾¤",
            "knowledge_map": "ç”Ÿæˆ Knowledge Map",
            "wordcloud": "ç”Ÿæˆæ–‡å­—é›²",
            "chart": "ç”Ÿæˆåœ–è¡¨",
            "report": "ç”Ÿæˆå ±å‘Š",
            "evaluate": "å“è³ªè©•ä¼°",
        }
        return {
            "current_step": current_step,
            "awaiting_human": False,
            "messages": [AIMessage(content=f"â³ æ­£åœ¨åŸ·è¡Œï¼š{step_names.get(next_step, next_step)}...")],
        }

    # æƒ…å¢ƒå››ï¼šæ‰€æœ‰æ­¥é©Ÿå·²å®Œæˆ
    return {
        "awaiting_human": True,
        "interrupt_message": "âœ… æ‰€æœ‰åˆ†æå·²å®Œæˆï¼æ˜¯å¦éœ€è¦èª¿æ•´ä»»ä½•éƒ¨åˆ†ï¼Ÿ",
        "messages": [AIMessage(content="âœ… æ‰€æœ‰åˆ†æå·²å®Œæˆï¼æ˜¯å¦éœ€è¦èª¿æ•´ä»»ä½•éƒ¨åˆ†ï¼Ÿ")],
    }
