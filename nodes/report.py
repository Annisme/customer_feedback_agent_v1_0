import json
from datetime import datetime
from langchain_core.messages import AIMessage
from langchain_openai import ChatOpenAI


def report_node(state: dict) -> dict:
    """Report ç¯€é»ï¼šæ ¹æ“šæ‰€æœ‰åˆ†æçµæœï¼Œç”± LLM ç”Ÿæˆæ”¹å–„å»ºè­°å ±å‘Šã€‚"""
    clusters = state.get("clusters")
    sentiment_result = state.get("sentiment_result")
    chart_paths = state.get("chart_paths", {})
    knowledge_map_path = state.get("knowledge_map_path")
    raw_data = state.get("raw_data", [])
    dataframe_summary = state.get("dataframe_summary", "")

    llm = ChatOpenAI(model="gpt-4.1", temperature=0.3)

    # çµ„è£åˆ†ææ‘˜è¦çµ¦ LLM
    analysis_parts = []

    analysis_parts.append(f"è³‡æ–™æ¦‚æ³ï¼š{dataframe_summary}")
    analysis_parts.append(f"ç¸½è³‡æ–™ç­†æ•¸ï¼š{len(raw_data)} ç­†")

    if sentiment_result:
        analysis_parts.append(
            f"æƒ…æ„Ÿåˆ†æï¼šæ­£é¢ {sentiment_result.get('æ­£é¢', 0)} ç­†ã€"
            f"è² é¢ {sentiment_result.get('è² é¢', 0)} ç­†ã€"
            f"ä¸­æ€§ {sentiment_result.get('ä¸­æ€§', 0)} ç­†"
        )

    if clusters:
        cluster_labels = clusters.get("cluster_labels", {})
        items = clusters.get("items", [])
        cluster_summary_parts = []
        for cid, label in cluster_labels.items():
            count = sum(1 for item in items if str(item.get("cluster_id")) == str(cid))
            # å–å¹¾å‰‡ç¯„ä¾‹
            examples = [item["content"] for item in items if str(item.get("cluster_id")) == str(cid)][:3]
            examples_text = "ï¼›".join(examples)
            cluster_summary_parts.append(f"ã€Œ{label}ã€({count}ç­†)ï¼š{examples_text}")
        analysis_parts.append("åˆ†ç¾¤çµæœï¼š\n" + "\n".join(cluster_summary_parts))

    if chart_paths:
        analysis_parts.append(f"å·²ç”Ÿæˆåœ–è¡¨ï¼š{', '.join(chart_paths.keys())}")

    if knowledge_map_path:
        analysis_parts.append("å·²ç”Ÿæˆ Knowledge Map")

    analysis_text = "\n\n".join(analysis_parts)

    prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å®¢æœå“è³ªåˆ†æé¡§å•ã€‚è«‹æ ¹æ“šä»¥ä¸‹åˆ†æçµæœï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„å®¢æˆ¶å›é¥‹åˆ†æå ±å‘Šã€‚

åˆ†æçµæœï¼š
{analysis_text}

è«‹ä½¿ç”¨ä»¥ä¸‹ Markdown æ ¼å¼è¼¸å‡ºå ±å‘Šï¼š

# é¡§å®¢å›é¥‹åˆ†æå ±å‘Š
**åˆ†ææ—¥æœŸ**ï¼š{datetime.now().strftime('%Y-%m-%d')}
**è³‡æ–™ç­†æ•¸**ï¼š{len(raw_data)} ç­†

## åŸ·è¡Œæ‘˜è¦
ï¼ˆç°¡è¦èªªæ˜æœ¬æ¬¡åˆ†æçš„æ•´é«”ç™¼ç¾ï¼Œ3-5 å¥è©±ï¼‰

## æƒ…æ„Ÿåˆ†æçµæœ
ï¼ˆæè¿°æ­£é¢/è² é¢/ä¸­æ€§æ¯”ä¾‹åŠå…¶å«ç¾©ï¼‰

## ä¸»è¦å•é¡Œåˆ†ç¾¤
ï¼ˆåˆ—å‡ºæ¯å€‹åˆ†ç¾¤çš„åç¨±ã€æ•¸é‡ã€ä¸»è¦å•é¡ŒåŠå…·é«”å›é¥‹ç¯„ä¾‹ï¼‰

## Knowledge Map æ´å¯Ÿ
ï¼ˆå¾ Knowledge Map çš„éšå±¤çµæ§‹ä¸­æå–çš„é—œéµæ´å¯Ÿï¼‰

## æ”¹å–„å»ºè­°
### çŸ­æœŸï¼ˆ1 å€‹æœˆå…§ï¼‰
ï¼ˆåˆ—å‡º 2-3 é …å¯ç«‹å³åŸ·è¡Œçš„æ”¹å–„æªæ–½ï¼‰

### ä¸­æœŸï¼ˆ3 å€‹æœˆå…§ï¼‰
ï¼ˆåˆ—å‡º 2-3 é …éœ€è¦è¦åŠƒåŸ·è¡Œçš„æ”¹å–„æªæ–½ï¼‰

### é•·æœŸï¼ˆ6 å€‹æœˆä»¥ä¸Šï¼‰
ï¼ˆåˆ—å‡º 1-2 é …ç­–ç•¥æ€§çš„æ”¹å–„æ–¹å‘ï¼‰

è«‹ç¢ºä¿å ±å‘Šå…§å®¹å…·é«”ã€å¯åŸ·è¡Œï¼Œä¸¦åŸºæ–¼å¯¦éš›æ•¸æ“šã€‚"""

    try:
        response = llm.invoke([
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å®¢æœå“è³ªåˆ†æé¡§å•ï¼Œæ“…é•·å¾æ•¸æ“šä¸­æå–æ´å¯Ÿä¸¦æå‡ºå¯åŸ·è¡Œçš„å»ºè­°ã€‚"},
            {"role": "user", "content": prompt},
        ])
        report = response.content
    except Exception as e:
        report = f"# é¡§å®¢å›é¥‹åˆ†æå ±å‘Š\n\n**åˆ†ææ—¥æœŸ**ï¼š{datetime.now().strftime('%Y-%m-%d')}\n\nâŒ å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}"

    # å„²å­˜å ±å‘Šåˆ°æª”æ¡ˆ
    import os
    output_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "outputs")
    os.makedirs(output_dir, exist_ok=True)
    report_path = os.path.join(output_dir, "report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)

    return {
        "report": report,
        "messages": [AIMessage(content=f"ğŸ“ æ”¹å–„å»ºè­°å ±å‘Šå·²ç”Ÿæˆï¼\n\n{report[:200]}...\n\nå®Œæ•´å ±å‘Šå·²å„²å­˜è‡³ï¼š{report_path}")],
    }
